---
title: "Case Study 2: Bellabeat Analysis"
author: "Erik Gonzalez"
date: "2023-08-03"
email: "egonzalez191991@gmail.com"
linkedin: "https://www.linkedin.com/in/gonzalez-erik/"
output: html_document
---

``` {r stop warning, include=FALSE}
knitr::opts_chunk$set(warning = FALSE)
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r Install packages, include=FALSE}
#install.packages("janitor")
#install.packages("skimr")
#install.packages("tidyverse")
```


```{r Load packages, include=FALSE}
library(janitor)
library(skimr)
library(tidyverse)
```


```{r set directory, include=FALSE}
#getwd() # displays your working directory
#setwd("F/RStudio/Code Dump/EG-Capstone-Project") # sets your working directory 
#getwd() # check you set your directory correctly
```

## Introduction:

Welcome to my Bellabeat analysis case study. Here, we will tackle the real-world challenges faced by Bellabeat, a smart device company based in San Francisco. Throughout this study, we will follow the data analysis process to answer key business questions and develop actionable insights.

The company's mission:
Become a larger player in the global smart device market.

Products:

* App: track activity, sleep, stress, menstrual cycle, and mindfulness habits.
* Wearable Device: connects to the app to track activity, sleep, and stress.
* Watch: connects to the app to track activity, sleep, and stress.
* Water Bottle: connects to the app to track daily water intake.
* Subscription membership: personalized guidance on nutrition, activity, sleep, health, beauty, and mindfulness based on their lifestyle and goals.

### Deliverables:

My task in the assignment is:

* Find out user usage for one device to gain insights on how people are using that device. Then take that information and make a high-level recommendation on how the trends can inform Bellabeat's marketing strategy.


### Problem:

I have been asked to focus on one of Bellabeat’s products and analyze smart device data to gain insight into how consumers are using their smart devices.
The insights I discover will then help guide the marketing strategy for the company.
You will present your analysis to the Bellabeat executive team (Sando Mur) along with your high-level recommendations for Bellabeat’s marketing strategy.


                   
                     
                     
## Ask - Step 1: Ask the right questions

Analyze other companies smart device usage data to gain insight into how consumers use non-Bellabeat smart devices. Select one Bellabeat product to apply these insights to in your presentation.

These questions will guide your analysis:

1. What are some trends in smart device usage?
2. How could these trends apply to Bellabeat customers?
3. How could these trends help influence Bellabeat's marketing strategy?



I will produce a report with the following deliverables:

1. A clear summary of the business task
2. A description of all data sources used: 
3. Documentation of any cleaning or manipulation of data
4. A summary of your analysis
5. Supporting visualizations and key findings
6. Your top high-level content recommendations based on your analysis


## Prepare - Step 2: Upload, inspect and clean the data

### Uploading

This Kaggle data set contains personal fitness trackers from thirty-three Fitbit users.
Thirty-three eligible Fitbit users consented to the submission of personal tracker data, including minute-level output for physical activity, heart rate, and sleep monitoring.
It includes information about daily activity, steps, and heart rate that can be used to explore users’ habits [Source](https://www.kaggle.com/arashnic)


* Since our goal is to essentially give broad strokes data about the Bellabeats users. We want to mainly focus on daily data and specifically the dailyActivity_merged file as our nexus. dailyActivity_merged has all the "daily" sheet titled columns already merged into it. Also, I will be adding values: day_of_week.

``` {r Upload datasets}
daily_activity <- read_csv("Fit Data/dailyActivity_merged.csv")
daily_sleep <- read_csv("Fit Data/sleepDay_merged.csv")
heartrate <- read_csv("Fit Data/heartrate_seconds_merged.csv")
weight_log <- read_csv("Fit Data/weightLogInfo_merged.csv")
```

### Inspecting

The first thing we must do is understand the data. If we know what each sheet contains and what each column represents, we can start forming a plan of action. Our initial goal is to find connections between the sheets; think of keys as in primary keys and foreign keys. This can take time, but it is worth it. Once you have grasped what information the data is presenting, only then can you start to address your stakeholder questions.

This data goes by:

* Daily Activity

* Calories: daily, hourly, and minute (narrow and wide).

* Intensities: daily, hourly, minute (narrow and wide).

* Steps: daily, hourly, minute (narrow and wide).

* Heart rate: seconds

* Sleep: daily, minute

* Weight log info

* METs: minute(narrow) what are METs? ANSWER: Metabolic Equivalent of Task: a unit of measurement that represents the energy expenditure of an activity relative to the resting metabolic rate METs are used to quantify the intensity of physical activities.

    * minute narrow: a lot of rows, not many columns.
My minuteIntentisitesNarrow csv has over 1 million rows /but/ only 3 columns.

    * minute wide: a lot of columns, not many rows.
My minuteIntentisitesWide csv has 21 thousand rows /but/ only 61 columns.
``` {r Inspect the data}
head(daily_activity)
head(daily_sleep)
head(heartrate)
``` 


* You can see all the NA in weight_log column "Fat" we'll fix that soon
``` {r Inspect the data2}
head(weight_log) 
``` 


``` {r Inspect the data once more}
str(daily_activity)
str(daily_sleep)
str(heartrate)
str(weight_log)
```

### Cleaning

* There are 33 total participates per daily_activity$Id
``` {r checking the total amount of unique users by "Id": }
n_unique(daily_activity$Id)  
n_unique(daily_sleep$Id)
n_unique(heartrate$Id)
n_unique(weight_log$Id)
```


```{r checking for duplicate values to eliminate} 
sum(duplicated(daily_activity))
sum(duplicated(heartrate))
sum(duplicated(weight_log))
```


* daily_sleep is the only object that has duplicates
```{r checking for duplicate values to eliminate1} 
sum(duplicated(daily_sleep)) 
```


* Three of the rows have duplicate data. We must remove them
``` {r displaying a tibble that contains the duplicates}
duplicates <- daily_sleep[duplicated(daily_sleep) | duplicated(daily_sleep, fromLast = TRUE), ]
View(duplicates)
daily_sleep <- daily_sleep[!duplicated(daily_sleep), ]
```


* We went from 413 rows to 410. All 3 duplicated rows have been removed
``` {r checking that the duplicates are gone.}
sum(duplicated(daily_sleep))
```