---
title: "Case Study 2: Bellabeat Analysis"
author: "Erik Gonzalez"
date: "2023-08-03"
email: "egonzalez191991@gmail.com"
linkedin: "https://www.linkedin.com/in/gonzalez-erik/"
output: html_document
---

``` {r stop warning, include=FALSE}
knitr::opts_chunk$set(warning = FALSE)
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r Install packages, include=FALSE}
#install.packages("janitor")
#install.packages("skimr")
#install.packages("tidyverse")
```


```{r Load packages, include=FALSE}
library(janitor)
library(skimr)
library(tidyverse)
```


```{r set directory, include=FALSE}
#getwd() # displays your working directory
#setwd("F/RStudio/Code Dump/EG-Capstone-Project") # sets your working directory 
#getwd() # check you set your directory correctly
```

## Introduction:

Welcome to my Bellabeat analysis case study. Here, we will tackle the real-world challenges faced by Bellabeat, a smart device company based in San Francisco. Throughout this study, we will follow the data analysis process to answer key business questions and develop actionable insights.

The company's mission:
Become a larger player in the global smart device market.

Products:

* App: track activity, sleep, stress, menstrual cycle, and mindfulness habits.
* Wearable Device: connects to the app to track activity, sleep, and stress.
* Watch: connects to the app to track activity, sleep, and stress.
* Water Bottle: connects to the app to track daily water intake.
* Subscription membership: personalized guidance on nutrition, activity, sleep, health, beauty, and mindfulness based on their lifestyle and goals.

### Deliverables:

My task in the assignment is:

* Find out user usage for one device to gain insights on how people are using that device. Then take that information and make a high-level recommendation on how the trends can inform Bellabeat's marketing strategy.


### Problem:

I have been asked to focus on one of Bellabeat’s products and analyze smart device data to gain insight into how consumers are using their smart devices.
The insights I discover will then help guide the marketing strategy for the company.
You will present your analysis to the Bellabeat executive team (Sando Mur) along with your high-level recommendations for Bellabeat’s marketing strategy.


                   
                     
                     
## Ask - Step 1: Ask the right questions

Analyze other companies smart device usage data to gain insight into how consumers use non-Bellabeat smart devices. Select one Bellabeat product to apply these insights to in your presentation.

These questions will guide your analysis:

1. What are some trends in smart device usage?
2. How could these trends apply to Bellabeat customers?
3. How could these trends help influence Bellabeat's marketing strategy?



I will produce a report with the following deliverables:

1. A clear summary of the business task
2. A description of all data sources used: 
3. Documentation of any cleaning or manipulation of data
4. A summary of your analysis
5. Supporting visualizations and key findings
6. Your top high-level content recommendations based on your analysis


## Prepare - Step 2: Upload, Inspect and Clean the Data

### Uploading

This Kaggle data set contains personal fitness trackers from thirty-three Fitbit users.
Thirty-three eligible Fitbit users consented to the submission of personal tracker data, including minute-level output for physical activity, heart rate, and sleep monitoring.
It includes information about daily activity, steps, and heart rate that can be used to explore users’ habits [Source](https://www.kaggle.com/arashnic)


* Since our goal is to essentially give broad strokes data about the Bellabeats users. We want to mainly focus on daily data and specifically the dailyActivity_merged file as our nexus. dailyActivity_merged has all the "daily" sheet titled columns already merged into it. Also, I will be adding values: day_of_week.

``` {r Upload datasets}
daily_activity <- read_csv("Fit Data/dailyActivity_merged.csv")
daily_sleep <- read_csv("Fit Data/sleepDay_merged.csv")
heartrate <- read_csv("Fit Data/heartrate_seconds_merged.csv")
weight_log <- read_csv("Fit Data/weightLogInfo_merged.csv")
```

### Inspecting

The first thing we must do is understand the data. If we know what each sheet contains and what each column represents, we can start forming a plan of action. Our initial goal is to find connections between the sheets; think of keys as in primary keys and foreign keys. This can take time, but it is worth it. Once you have grasped what information the data is presenting, only then can you start to address your stakeholder questions.

This data goes by:

* Daily Activity

* Calories: daily, hourly, and minute (narrow and wide).

* Intensities: daily, hourly, minute (narrow and wide).

* Steps: daily, hourly, minute (narrow and wide).

* Heart rate: seconds

* Sleep: daily, minute

* Weight log info

* METs: minute(narrow) what are METs? ANSWER: Metabolic Equivalent of Task: a unit of measurement that represents the energy expenditure of an activity relative to the resting metabolic rate METs are used to quantify the intensity of physical activities.

    * minute narrow: a lot of rows, not many columns.
My minuteIntentisitesNarrow csv has over 1 million rows /but/ only 3 columns.

    * minute wide: a lot of columns, not many rows.
My minuteIntentisitesWide csv has 21 thousand rows /but/ only 61 columns.
``` {r Inspect the data}
head(daily_activity)
head(daily_sleep)
head(heartrate)
``` 


* You can see all the NA in weight_log column "Fat" we'll fix that soon
``` {r Inspect the data2}
head(weight_log) 
``` 


``` {r Inspect the data once more}
str(daily_activity)
str(daily_sleep)
str(heartrate)
str(weight_log)
```

### Cleaning

* There are 33 total participates per daily_activity$Id
``` {r checking the total amount of unique users by "Id": }
n_unique(daily_activity$Id)  
n_unique(daily_sleep$Id)
n_unique(heartrate$Id)
n_unique(weight_log$Id)
```


```{r checking for duplicate values to eliminate} 
sum(duplicated(daily_activity))
sum(duplicated(heartrate))
sum(duplicated(weight_log))
```


* daily_sleep is the only object that has duplicates
```{r checking for duplicate values to eliminate1} 
sum(duplicated(daily_sleep)) 
```


* Three of the rows have duplicate data. We must remove them
``` {r displaying a tibble that contains the duplicates}
duplicates <- daily_sleep[duplicated(daily_sleep) | duplicated(daily_sleep, fromLast = TRUE), ]
View(duplicates)
daily_sleep <- daily_sleep[!duplicated(daily_sleep), ]
```


* We went from 413 rows to 410. All 3 duplicated rows have been removed
``` {r checking that the duplicates are gone.}
sum(duplicated(daily_sleep))
```


``` {r checking for any missing values}
any(is.na(daily_activity))
any(is.na(daily_sleep))
any(is.na(heartrate))
```


* weight_log is the only object that has missing values 
``` {r checking for any missing values1}
any(is.na(weight_log))
```


* Only 2 rows of the entire column "Fat" have data. In this situation, without 
any actual stakeholders to communicate with; our only solution is to remove 
the whole column. If we remove every row with empty data, we'll be left with 2.
``` {r displaying the tibble that contains the missing values}
head(weight_log)
```


* We went from 8 columns to 7. Column "Fat" has been removed
``` {r removing the column "Fat" from weight_log}
weight_log <- weight_log[, -which(names(weight_log) == "Fat")]
head(weight_log)
```


* Now our data is clean
``` {r removing the extra object}
rm(duplicates)
```


## Process - Step 3: Performing Data Analysis Procedures


Since our goal is to essentially give broad strokes data about the Bellabeats users, we want to mainly focus on daily data, specifically the "dailyActivity_merged" file, as our nexus. "dailyActivity_merged" has all the "daily" sheet-titled columns already merged into it, simplifying the process and giving us a clear starting point.


Other sheets that can be useful here are:

* heartrate_seconds_merged: However, all we will be using this for is a summary(). The heart rate sheet has good data but was only used by 14 of the 33 participants in the study, leaving it with subpar data.

* sleepDay_merged: However, a column needs to be created to allow proper plotting later on.

* weight_log: However, all we will be using this for is a summary(). The weight sheet has poor data, inconsistent times of measurement, and, most importantly, is only used by 8 of the 33 volunteers sharing their data, leaving it with subpar data.


``` {r daily_activity summary}
daily_activity %>%  
  select(TotalSteps,
         TotalDistance,
         SedentaryMinutes) %>%
  summary()
```


``` {r daily_activity per category in minutes}
daily_activity%>%
  select(VeryActiveMinutes, FairlyActiveMinutes, LightlyActiveMinutes) %>%
  summary()
```


``` {r daily_activity calories}
daily_activity %>%  
  select(Calories) %>%
  summary()
```


``` {r daily_sleep summary}
daily_sleep %>%
  select(TotalMinutesAsleep, TotalTimeInBed, TotalSleepRecords) %>%
  summary()
```


``` {r weight summary}
weight_log  %>%
  select(WeightPounds, BMI) %>%
  summary()
```


``` {r heartrate summary}
heartrate %>%
  select(Value) %>%
  summary()
```


## Analyze - Step 4: Analysis


My predictions based on current analysis:

  * People will get most rest on the weekends
  * The week days will contain the most amount of steps
  * The more activity the more calories people will consume
  * The more time in bed the more sleep will be accomplished
  * The more steps someone takes the better their rest will be
  * The more steps people take the more calories people will consume
  * Users will be sedentary the vast majority of their day
  

## Share - Step 5: Data Visualization


### Daily Sleep Pot


